import requests
from bs4 import BeautifulSoup
import re
import time
from typing import Dict, Optional

class RusprofileParser:
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–∏ —Å Rusprofile.ru"""
    
    def __init__(self):
        self.base_url = "https://www.rusprofile.ru"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3',
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
    
    def get_company_info(self, inn: str) -> Optional[Dict]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥: –ø–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏ –ø–æ –ò–ù–ù"""
        try:
            # 1. –ü–æ–ª—É—á–∞–µ–º HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–æ–º–ø–∞–Ω–∏–∏
            html = self._fetch_company_page(inn)
            if not html:
                return None
            
            # 2. –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ
            soup = BeautifulSoup(html, 'html.parser')
            
            company_data = {
                'inn': inn,
                'name': self._extract_name(soup),
                'revenue': self._extract_revenue(soup),
                'employees': self._extract_employees(soup),
                'site': self._extract_website(soup),
                'okved_main': self._extract_okved(soup),
                'full_address': self._extract_address(soup),
                'ceo': self._extract_ceo(soup),
                'registration_date': self._extract_reg_date(soup),
                'status': self._extract_status(soup)
            }
            
            return company_data
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –∫–æ–º–ø–∞–Ω–∏–∏ {inn}: {e}")
            return None
    
    def _fetch_company_page(self, inn: str) -> Optional[str]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É –∫–æ–º–ø–∞–Ω–∏–∏"""
        try:
            search_url = f"{self.base_url}/search?query={inn}&type=ul"
            response = self.session.get(search_url, timeout=10)
            response.raise_for_status()
            
            # –ò—â–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –∫–∞—Ä—Ç–æ—á–∫—É –∫–æ–º–ø–∞–Ω–∏–∏
            soup = BeautifulSoup(response.text, 'html.parser')
            company_link = soup.find('a', class_='company-item')
            
            if company_link and 'href' in company_link.attrs:
                company_url = self.base_url + company_link['href']
                print(f"üîó –ù–∞–π–¥–µ–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞: {company_url}")
                
                time.sleep(1)  # –£–≤–∞–∂–∞–µ–º —Å–µ—Ä–≤–µ—Ä
                company_response = self.session.get(company_url, timeout=10)
                company_response.raise_for_status()
                
                return company_response.text
            else:
                print(f"‚ö†Ô∏è –ö–æ–º–ø–∞–Ω–∏—è —Å –ò–ù–ù {inn} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return None
                
        except requests.exceptions.RequestException as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –¥–ª—è –ò–ù–ù {inn}: {e}")
            return None
    
    def _extract_name(self, soup: BeautifulSoup) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏"""
        try:
            name_tag = soup.find('h1', class_='company-name')
            if name_tag:
                return name_tag.get_text(strip=True)
            
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫
            name_tag = soup.find('div', {'itemprop': 'name'})
            if name_tag:
                return name_tag.get_text(strip=True)
        except:
            pass
        return f"–ö–æ–º–ø–∞–Ω–∏—è_{soup.find('title').get_text()[:50]}"
    
    def _extract_revenue(self, soup: BeautifulSoup) -> int:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—ã—Ä—É—á–∫—É (–ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–æ—Å—Ç—É–ø–Ω—ã–π –≥–æ–¥)"""
        try:
            # –ò—â–µ–º –±–ª–æ–∫ —Å —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º–∏
            fin_section = soup.find('div', class_='company-requisites')
            if not fin_section:
                fin_section = soup.find('section', id='finance')
            
            if fin_section:
                # –ò—â–µ–º –≤—ã—Ä—É—á–∫—É –ø–æ —Ç–µ–∫—Å—Ç—É
                fin_text = fin_section.get_text()
                
                # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤—ã—Ä—É—á–∫–∏
                patterns = [
                    r'–í—ã—Ä—É—á–∫–∞[^0-9]*([0-9, ]+)\s*(—Ç—ã—Å|–º–ª–Ω|–º–ª—Ä–¥|‚ÇΩ|—Ä—É–±)',
                    r'Revenue[^0-9]*([0-9, ]+)\s*(—Ç—ã—Å|–º–ª–Ω|–º–ª—Ä–¥|‚ÇΩ|—Ä—Éb)',
                    r'–í–´–†–£–ß–ö–ê[^0-9]*([0-9, ]+)\s*(—Ç—ã—Å|–º–ª–Ω|–º–ª—Ä–¥|‚ÇΩ|—Ä—É–±)'
                ]
                
                for pattern in patterns:
                    match = re.search(pattern, fin_text, re.IGNORECASE)
                    if match:
                        revenue_str = match.group(1).replace(' ', '').replace(',', '.')
                        multiplier = self._get_multiplier(match.group(2).lower() if match.group(2) else '')
                        revenue = float(revenue_str) * multiplier
                        return int(revenue)
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ –±–ª–æ–∫–µ, –∏—â–µ–º –≤ —Ç–∞–±–ª–∏—Ü–µ
            revenue_cells = soup.find_all('td', string=re.compile(r'–í—ã—Ä—É—á–∫–∞|Revenue', re.I))
            for cell in revenue_cells:
                next_cell = cell.find_next('td')
                if next_cell:
                    value_text = next_cell.get_text(strip=True)
                    return self._parse_financial_value(value_text)
                    
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤—ã—Ä—É—á–∫–∏: {e}")
        
        return 0
    
    def _extract_employees(self, soup: BeautifulSoup) -> Optional[int]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤"""
        try:
            # –ò—â–µ–º –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            employee_text = soup.find(string=re.compile(r'—Å–æ—Ç—Ä—É–¥–Ω–∏–∫|—Ä–∞–±–æ—Ç–Ω–∏–∫|–ø–µ—Ä—Å–æ–Ω–∞–ª|employees|staff', re.I))
            if employee_text:
                # –ò—â–µ–º —á–∏—Å–ª–æ —Ä—è–¥–æ–º —Å —Ç–µ–∫—Å—Ç–æ–º
                parent = employee_text.parent
                if parent:
                    text = parent.get_text()
                    match = re.search(r'(\d[\d ]*)\s*—Å–æ—Ç—Ä—É–¥–Ω–∏–∫', text, re.I)
                    if match:
                        return int(match.group(1).replace(' ', ''))
            
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –≤ –±–ª–æ–∫–µ "–û–±—â–∏–µ —Å–≤–µ–¥–µ–Ω–∏—è"
            info_section = soup.find('div', class_='company-info')
            if info_section:
                text = info_section.get_text()
                matches = re.findall(r'(\d+)\s*(?:—á–µ–ª–æ–≤–µ–∫|—Å–æ—Ç—Ä—É–¥–Ω–∏–∫|—Ä–∞–±–æ—Ç–Ω–∏–∫)', text, re.I)
                if matches:
                    return int(matches[-1])
                    
        except:
            pass
        return None
    
    def _extract_website(self, soup: BeautifulSoup) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–∞–π—Ç –∫–æ–º–ø–∞–Ω–∏–∏"""
        try:
            # –ò—â–µ–º —Å—Å—ã–ª–∫—É —Å –∫–ª–∞—Å—Å–æ–º –∏–ª–∏ –∞—Ç—Ä–∏–±—É—Ç–æ–º
            website_tag = soup.find('a', {'class': re.compile(r'website|site|url', re.I)})
            if not website_tag:
                website_tag = soup.find('a', href=re.compile(r'^https?://'))
            
            if website_tag and 'href' in website_tag.attrs:
                url = website_tag['href']
                if not url.startswith('http'):
                    url = 'http://' + url
                return url
                
        except:
            pass
        return None
    
    def _extract_okved(self, soup: BeautifulSoup) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –û–ö–í–≠–î"""
        try:
            # –ò—â–µ–º –û–ö–í–≠–î –≤ —Ç–µ–∫—Å—Ç–µ
            okved_tags = soup.find_all(string=re.compile(r'–û–ö–í–≠–î|–û–ö–í–≠–î2|–í–∏–¥ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏', re.I))
            for tag in okved_tags:
                parent = tag.parent
                if parent:
                    # –ò—â–µ–º –∫–æ–¥ –û–ö–í–≠–î (—Ñ–æ—Ä–º–∞—Ç XX.XX –∏–ª–∏ XX.XX.X)
                    text = parent.get_text()
                    match = re.search(r'(\d{2}\.\d{2}(?:\.\d{1,2})?)', text)
                    if match:
                        return match.group(1)
            
            # –ü–æ–∏—Å–∫ –≤ –±–ª–æ–∫–µ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            activity_section = soup.find('div', class_=re.compile(r'activity|business|–¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å', re.I))
            if activity_section:
                text = activity_section.get_text()
                match = re.search(r'(\d{2}\.\d{2}(?:\.\d{1,2})?)', text)
                if match:
                    return match.group(1)
                    
        except:
            pass
        return None
    
    def _extract_address(self, soup: BeautifulSoup) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –∞–¥—Ä–µ—Å"""
        try:
            address_tag = soup.find('span', {'itemprop': 'address'})
            if not address_tag:
                address_tag = soup.find('div', class_='company-address')
            
            if address_tag:
                return address_tag.get_text(strip=True)
                
        except:
            pass
        return None
    
    def _extract_ceo(self, soup: BeautifulSoup) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –§–ò–û –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞"""
        try:
            ceo_tags = soup.find_all(string=re.compile(r'–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä|–î–∏—Ä–µ–∫—Ç–æ—Ä|–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å|CEO', re.I))
            for tag in ceo_tags:
                parent = tag.parent
                if parent:
                    # –ë–µ—Ä–µ–º —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –ø–æ—Å–ª–µ "–î–∏—Ä–µ–∫—Ç–æ—Ä"
                    text = parent.get_text()
                    # –ò—â–µ–º –§–ò–û (—Ä—É—Å—Å–∫–∏–µ –±—É–∫–≤—ã, –ø—Ä–æ–±–µ–ª—ã, –¥–µ—Ñ–∏—Å—ã)
                    match = re.search(r'(?:–î–∏—Ä–µ–∫—Ç–æ—Ä|–ì–µ–Ω\.\s*–¥–∏—Ä–µ–∫—Ç–æ—Ä|–†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å)[:\s]+([–ê-–Ø–Å][–∞-—è—ë]+\s+[–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å][–∞-—è—ë]+)?)', text)
                    if match:
                        return match.group(1)
        except:
            pass
        return None
    
    def _extract_reg_date(self, soup: BeautifulSoup) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞—Ç—É —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏"""
        try:
            reg_tags = soup.find_all(string=re.compile(r'–î–∞—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏|–ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∞|–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è', re.I))
            for tag in reg_tags:
                parent = tag.parent
                if parent:
                    text = parent.get_text()
                    # –ò—â–µ–º –¥–∞—Ç—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ –î–î.–ú–ú.–ì–ì–ì–ì
                    match = re.search(r'(\d{2}\.\d{2}\.\d{4})', text)
                    if match:
                        return match.group(1)
        except:
            pass
        return None
    
    def _extract_status(self, soup: BeautifulSoup) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å –∫–æ–º–ø–∞–Ω–∏–∏"""
        try:
            status_tags = soup.find_all(string=re.compile(r'–°—Ç–∞—Ç—É—Å|–°–æ—Å—Ç–æ—è–Ω–∏–µ|Status', re.I))
            for tag in status_tags:
                parent = tag.parent
                if parent:
                    text = parent.get_text()
                    if re.search(r'–¥–µ–π—Å—Ç–≤—É—é—â|active|working', text, re.I):
                        return '–î–µ–π—Å—Ç–≤—É—é—â–∞—è'
                    elif re.search(r'–ª–∏–∫–≤–∏–¥–∏—Ä|–±–∞–Ω–∫—Ä–æ—Ç|liquidated|bankrupt', text, re.I):
                        return '–õ–∏–∫–≤–∏–¥–∏—Ä–æ–≤–∞–Ω–∞'
        except:
            pass
        return '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
    
    def _parse_financial_value(self, text: str) -> int:
        """–ü–∞—Ä—Å–∏—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å –º–Ω–æ–∂–∏—Ç–µ–ª—è–º–∏ (—Ç—ã—Å, –º–ª–Ω, –º–ª—Ä–¥)"""
        try:
            text = text.lower().strip()
            # –£–¥–∞–ª—è–µ–º –≤–∞–ª—é—Ç—É –∏ –ø—Ä–æ–±–µ–ª—ã
            text = re.sub(r'[‚ÇΩ—Ä—É–±$‚Ç¨]', '', text)
            text = text.replace(' ', '').replace(',', '.')
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–Ω–æ–∂–∏—Ç–µ–ª—å
            multiplier = 1
            if '–º–ª—Ä–¥' in text:
                multiplier = 1_000_000_000
                text = text.replace('–º–ª—Ä–¥', '')
            elif '–º–ª–Ω' in text:
                multiplier = 1_000_000
                text = text.replace('–º–ª–Ω', '')
            elif '—Ç—ã—Å' in text:
                multiplier = 1_000
                text = text.replace('—Ç—ã—Å', '')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ
            match = re.search(r'(\d+\.?\d*)', text)
            if match:
                return int(float(match.group(1)) * multiplier)
        except:
            pass
        return 0
    
    def _get_multiplier(self, unit: str) -> int:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–∏—Å–ª–æ–≤–æ–π –º–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è"""
        multipliers = {
            '—Ç—ã—Å': 1_000,
            '–º–ª–Ω': 1_000_000,
            '–º–ª—Ä–¥': 1_000_000_000,
            '—Ç—Ä–ª–Ω': 1_000_000_000_000,
            'k': 1_000,
            'm': 1_000_000,
            'b': 1_000_000_000
        }
        return multipliers.get(unit.lower(), 1)
    
    def search_by_name(self, company_name: str, limit: int = 10) -> list:
        """–ò—â–µ—Ç –∫–æ–º–ø–∞–Ω–∏–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ò–ù–ù)"""
        try:
            search_query = company_name.replace(' ', '+')
            url = f"{self.base_url}/search?query={search_query}"
            
            response = self.session.get(url, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            companies = []
            company_items = soup.find_all('div', class_='company-item')
            
            for item in company_items[:limit]:
                inn_tag = item.find('span', string=re.compile(r'–ò–ù–ù'))
                if inn_tag:
                    inn_text = inn_tag.get_text()
                    inn_match = re.search(r'\b\d{10,12}\b', inn_text)
                    if inn_match:
                        companies.append({
                            'inn': inn_match.group(0),
                            'name': item.find('a', class_='company-item-title').get_text(strip=True) if item.find('a', class_='company-item-title') else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
                        })
            
            return companies
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é: {e}")
            return []

# --- –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è ---
if __name__ == "__main__":
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞ Rusprofile")
    parser = RusprofileParser()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –ò–ù–ù –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π
    test_inns = [
        "4574170000",  # 1C
        "7736207543",  # –Ø–Ω–¥–µ–∫—Å
        "7707049388",  # –°–±–µ—Ä
        "7727734900"   # –¢–∏–Ω—å–∫–æ—Ñ—Ñ
    ]
    
    for inn in test_inns:
        print(f"\nüìä –ü–∞—Ä—Å–∏–º –∫–æ–º–ø–∞–Ω–∏—é —Å –ò–ù–ù {inn}...")
        data = parser.get_company_info(inn)
        
        if data:
            print(f"‚úÖ –ù–∞–∑–≤–∞–Ω–∏–µ: {data.get('name')}")
            print(f"   –í—ã—Ä—É—á–∫–∞: {data.get('revenue'):,} —Ä—É–±" if data.get('revenue') else "   –í—ã—Ä—É—á–∫–∞: –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            print(f"   –°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏: {data.get('employees')}" if data.get('employees') else "   –°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            print(f"   –°–∞–π—Ç: {data.get('site')}" if data.get('site') else "   –°–∞–π—Ç: –Ω–µ –Ω–∞–π–¥–µ–Ω")
            print(f"   –û–ö–í–≠–î: {data.get('okved_main')}" if data.get('okved_main') else "   –û–ö–í–≠–î: –Ω–µ –Ω–∞–π–¥–µ–Ω")
            print(f"   –°—Ç–∞—Ç—É—Å: {data.get('status')}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—Ä–∏—Ç–µ—Ä–∏–π 100 –º–ª–Ω —Ä—É–±–ª–µ–π
            if data.get('revenue', 0) >= 100_000_000:
                print("   üü¢ –ö—Ä–∏—Ç–µ—Ä–∏–π –≤—ã—Ä—É—á–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω (>100 –º–ª–Ω —Ä—É–±)")
            else:
                print("   üî¥ –ö—Ä–∏—Ç–µ—Ä–∏–π –≤—ã—Ä—É—á–∫–∏ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω")
        else:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
        
        time.sleep(2)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
